<<<<<<< Updated upstream
# titanic-data-predictor
=======
# ğŸš¢ Titanic Data Predictor  
### Northwestern University â€“ MLDS 413: Introduction to Data Engineering  
**Homework 3**

---

## ğŸ“˜ Overview

This project builds **two reproducible Docker environments** â€” one in **Python** and one in **R** â€” to analyze passenger data from the Titanic disaster (April 15, 1912) and predict survival outcomes using logistic regression.

Each Dockerfile runs independently and produces printed outputs directly in the terminal.  
The grader can reproduce results by simply cloning this repository, downloading the dataset, and running two commands per environment.

---

## ğŸ“‚ Repository Structure

```plaintext
titanic-data-predictor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                     # contains local CSV files (not committed)
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â””â”€â”€ gender_submission.csv
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ titanic_model.py
â”‚   â””â”€â”€ r/
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ install_package.R
â”‚       â””â”€â”€ titanic_model.R
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile                    # Python environment
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ğŸ“Š Dataset

The dataset is provided by Kaggleâ€™s Titanic: Machine Learning from Disaster
 competition.

Required files

After downloading from Kaggle, youâ€™ll have:

train.csv

test.csv

gender_submission.csv

Before building your Docker images, make sure these files are placed correctly:

1ï¸âƒ£ Create the data folder (if it doesnâ€™t exist):

mkdir -p src/data


2ï¸âƒ£ Move the CSV files into that folder:

src/data/train.csv
src/data/test.csv
src/data/gender_submission.csv


ğŸ Python Container
ğŸ§© Purpose

Builds a Python environment that reads Titanic data, cleans missing values, trains a logistic regression model, and evaluates accuracy on both train and test datasets.

ğŸªœ Steps to Run

1ï¸âƒ£ Build the Docker image

docker build -t titanic-py .


2ï¸âƒ£ Run the container

docker run titanic-py

ğŸ§¾ Expected Output
Loading data...
Training logistic regression...
Training accuracy: 0.799
Testing accuracy: 0.768
Predictions saved to src/data/titanic_predictions.csv

ğŸ§  Technical Details

Base image: python:3.12-slim

Dependencies: from requirements.txt

pandas
numpy
scikit-learn
joblib


Model: sklearn.linear_model.LogisticRegression

Output: src/data/titanic_predictions.csv

ğŸ“ˆ R Container
ğŸ§© Purpose

Builds an R environment that loads the Titanic dataset, performs data cleaning, trains a logistic regression model, and prints performance metrics.

ğŸªœ Steps to Run

1ï¸âƒ£ Build the Docker image

docker build -t titanic-r -f src/r/Dockerfile .


2ï¸âƒ£ Run the container

docker run titanic-r

ğŸ§¾ Expected Output
Step 1: Loading data...
train.csv shape: 891 rows, 12 columns
test.csv shape: 418 rows, 11 columns
Step 2: Cleaning data...
Step 3: Training logistic regression...
Training accuracy: 0.799
Step 4: Predicting on test.csv...
Match rate vs gender_submission.csv: 0.938
Step 5: Saving predictions...
Saved: src/data/titanic_predictions_r.csv
Script finished successfully.

ğŸ§  Technical Details

Base image: rocker/tidyverse:4.3.2

Includes the full tidyverse (dplyr, ggplot2, readr, tidyr, etc.) pre-installed
for fast, reproducible builds.

Additional package installed:

install.packages("caret", repos="https://packagemanager.posit.co/cran/__linux__/jammy/latest")


Model: glm() logistic regression

Output: src/data/titanic_predictions_r.csv


ğŸ§ª Reproducibility Notes

Both Dockerfiles are fully automated.

No manual package installation once the dataset is present.

Outputs print directly in the terminal.

The R image uses rocker/tidyverse for guaranteed dependency stability.



âœï¸ Author

Tyrone Li
Northwestern University
MLDS 413 â€“ Introduction to Data Engineering
Fall 2025
>>>>>>> Stashed changes
